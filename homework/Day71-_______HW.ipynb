{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cj4tE8e8iUtO"
   },
   "source": [
    "\n",
    "\n",
    "# 作業目標:\n",
    "\n",
    "    1. 藉由固定的 dataset, 來驗證不同loss function\n",
    "    2. Dataset 的特性跟我們選用的loss function 對accracy 的影響\n",
    "    \n",
    "    \n",
    "# 作業重點: \n",
    "    請分別選用 \"MSE\", \"binary _crossentropy\"\n",
    "    查看Train/test accurancy and loss rate\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R51J4KyyiUsL"
   },
   "source": [
    "# 導入必要的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qd68OQjciUsM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxKuzQLQiUsP"
   },
   "source": [
    "# 資料準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIbFZdTCiUsQ"
   },
   "outputs": [],
   "source": [
    "#取得Keras Dataset\n",
    "(x_img_train,y_label_train),(x_img_test,y_label_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8CJVjNOiUsS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: images: (50000, 32, 32, 3)  labels: (50000, 1)\n",
      "test  data: images: (10000, 32, 32, 3)  labels: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#確認 CIFAR10 Dataset 資料維度\n",
    "print(\"train data:\",'images:',x_img_train.shape,\n",
    "      \" labels:\",y_label_train.shape) \n",
    "print(\"test  data:\",'images:',x_img_test.shape ,\n",
    "      \" labels:\",y_label_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3P6P4DXiUsV"
   },
   "outputs": [],
   "source": [
    "#資料正規化\n",
    "x_img_train_normalize = x_img_train.astype('float32') / 255.0\n",
    "x_img_test_normalize = x_img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vsDyjKYliUsX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#針對Label 做 ONE HOT ENCODE\n",
    "from keras.utils import np_utils\n",
    "y_label_train_OneHot = np_utils.to_categorical(y_label_train)\n",
    "y_label_test_OneHot = np_utils.to_categorical(y_label_test)\n",
    "y_label_test_OneHot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RutW2OtgiUsZ"
   },
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHz592aXiUsa"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hslqrIp0iUse"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hqe35hs2iUsi"
   },
   "outputs": [],
   "source": [
    "#卷積層1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED7dqe1YiUsm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.add(Conv2D(filters=32,kernel_size=(3,3),\n",
    "                 input_shape=(32, 32,3), \n",
    "                 activation='relu', \n",
    "                 padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), \n",
    "                 activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), \n",
    "                 activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3, 3), \n",
    "                 activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(filters=32,kernel_size=(3,3),\n",
    "#                  input_shape=(32, 32,3), \n",
    "#                  activation='relu', \n",
    "#                  padding='same'))\n",
    "\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(filters=64, kernel_size=(3, 3), \n",
    "#                  activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxzRIjR0iUtH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,181,002\n",
      "Trainable params: 1,181,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#檢查model 的STACK\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJCtpJM0iUtJ"
   },
   "source": [
    "# 載入之前訓練的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JU3A6NzQiUtK"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(\"SaveModel/cifarCnnModel.h5\")\n",
    "    print(\"載入模型成功!繼續訓練模型\")\n",
    "except :    \n",
    "    print(\"載入模型失敗!開始訓練一個新模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBbCuziziUtM"
   },
   "source": [
    "# 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6BiBcseiUtP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/12\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "37500/37500 [==============================] - 14s 376us/step - loss: 1.6082 - acc: 0.4038 - val_loss: 1.2659 - val_acc: 0.5339\n",
      "Epoch 2/12\n",
      "37500/37500 [==============================] - 6s 162us/step - loss: 1.1440 - acc: 0.5865 - val_loss: 1.0297 - val_acc: 0.6426\n",
      "Epoch 3/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.9295 - acc: 0.6688 - val_loss: 0.9376 - val_acc: 0.6745\n",
      "Epoch 4/12\n",
      "37500/37500 [==============================] - 6s 159us/step - loss: 0.7721 - acc: 0.7249 - val_loss: 0.8406 - val_acc: 0.7107\n",
      "Epoch 5/12\n",
      "37500/37500 [==============================] - 6s 159us/step - loss: 0.6512 - acc: 0.7705 - val_loss: 0.8179 - val_acc: 0.7171\n",
      "Epoch 6/12\n",
      "37500/37500 [==============================] - 6s 159us/step - loss: 0.5367 - acc: 0.8105 - val_loss: 0.8477 - val_acc: 0.7188\n",
      "Epoch 7/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.4591 - acc: 0.8378 - val_loss: 0.8450 - val_acc: 0.7229\n",
      "Epoch 8/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.3585 - acc: 0.8735 - val_loss: 0.9121 - val_acc: 0.7244\n",
      "Epoch 9/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.2849 - acc: 0.9002 - val_loss: 0.9342 - val_acc: 0.7246\n",
      "Epoch 10/12\n",
      "37500/37500 [==============================] - 6s 161us/step - loss: 0.2183 - acc: 0.9225 - val_loss: 1.0498 - val_acc: 0.7359\n",
      "Epoch 11/12\n",
      "37500/37500 [==============================] - 6s 161us/step - loss: 0.1990 - acc: 0.9283 - val_loss: 1.1100 - val_acc: 0.7266\n",
      "Epoch 12/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.1457 - acc: 0.9495 - val_loss: 1.2054 - val_acc: 0.7335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x145b5a4d198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "作業:\n",
    "請分別選用 \"MSE\", \"binary _crossentropy\"\n",
    "查看Train/test accurancy and loss rate\n",
    "'''\n",
    "functions = [\"categorical_crossentropy\", \"MSE\", \"binary _crossentropy\"]\n",
    " \n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_img_train_normalize,\n",
    "          y_label_train_OneHot, \n",
    "          validation_split=0.25,\n",
    "          epochs=12, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 127us/step\n",
      "\n",
      "accuracy 0.7226\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "print()\n",
    "print('accuracy',scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/12\n",
      "37500/37500 [==============================] - 7s 181us/step - loss: 0.0086 - acc: 0.9423 - val_loss: 0.0460 - val_acc: 0.7158\n",
      "Epoch 2/12\n",
      "37500/37500 [==============================] - 6s 158us/step - loss: 0.0090 - acc: 0.9409 - val_loss: 0.0458 - val_acc: 0.7150\n",
      "Epoch 3/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.0074 - acc: 0.9511 - val_loss: 0.0467 - val_acc: 0.7158\n",
      "Epoch 4/12\n",
      "37500/37500 [==============================] - 6s 158us/step - loss: 0.0078 - acc: 0.9479 - val_loss: 0.0461 - val_acc: 0.7184\n",
      "Epoch 5/12\n",
      "37500/37500 [==============================] - 6s 157us/step - loss: 0.0077 - acc: 0.9494 - val_loss: 0.0465 - val_acc: 0.7162\n",
      "Epoch 6/12\n",
      "37500/37500 [==============================] - 6s 157us/step - loss: 0.0074 - acc: 0.9503 - val_loss: 0.0461 - val_acc: 0.7175\n",
      "Epoch 7/12\n",
      "37500/37500 [==============================] - 6s 157us/step - loss: 0.0060 - acc: 0.9609 - val_loss: 0.0467 - val_acc: 0.7197\n",
      "Epoch 8/12\n",
      "37500/37500 [==============================] - 6s 158us/step - loss: 0.0069 - acc: 0.9546 - val_loss: 0.0485 - val_acc: 0.7046\n",
      "Epoch 9/12\n",
      "37500/37500 [==============================] - 6s 158us/step - loss: 0.0065 - acc: 0.9571 - val_loss: 0.0468 - val_acc: 0.7164\n",
      "Epoch 10/12\n",
      "37500/37500 [==============================] - 6s 157us/step - loss: 0.0057 - acc: 0.9621 - val_loss: 0.0480 - val_acc: 0.7114\n",
      "Epoch 11/12\n",
      "37500/37500 [==============================] - 6s 157us/step - loss: 0.0060 - acc: 0.9610 - val_loss: 0.0469 - val_acc: 0.7203\n",
      "Epoch 12/12\n",
      "37500/37500 [==============================] - 6s 159us/step - loss: 0.0060 - acc: 0.9612 - val_loss: 0.0458 - val_acc: 0.7245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x145b5cfc7b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"MSE\", optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_img_train_normalize,\n",
    "          y_label_train_OneHot, \n",
    "          validation_split=0.25,\n",
    "          epochs=12, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 104us/step\n",
      "\n",
      "accuracy 0.7109\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "print()\n",
    "print('accuracy',scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/12\n",
      "37500/37500 [==============================] - 7s 184us/step - loss: 0.0186 - acc: 0.9936 - val_loss: 0.2448 - val_acc: 0.9465\n",
      "Epoch 2/12\n",
      "37500/37500 [==============================] - 6s 161us/step - loss: 0.0137 - acc: 0.9953 - val_loss: 0.2521 - val_acc: 0.9470\n",
      "Epoch 3/12\n",
      "37500/37500 [==============================] - 6s 161us/step - loss: 0.0136 - acc: 0.9953 - val_loss: 0.2668 - val_acc: 0.9471\n",
      "Epoch 4/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.0121 - acc: 0.9958 - val_loss: 0.2604 - val_acc: 0.9467\n",
      "Epoch 5/12\n",
      "37500/37500 [==============================] - 6s 159us/step - loss: 0.0112 - acc: 0.9961 - val_loss: 0.2646 - val_acc: 0.9471\n",
      "Epoch 6/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.0111 - acc: 0.9962 - val_loss: 0.2615 - val_acc: 0.9450\n",
      "Epoch 7/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.0125 - acc: 0.9957 - val_loss: 0.2564 - val_acc: 0.9463\n",
      "Epoch 8/12\n",
      "37500/37500 [==============================] - 6s 159us/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.2842 - val_acc: 0.9449\n",
      "Epoch 9/12\n",
      "37500/37500 [==============================] - 6s 162us/step - loss: 0.0099 - acc: 0.9966 - val_loss: 0.2788 - val_acc: 0.9446\n",
      "Epoch 10/12\n",
      "37500/37500 [==============================] - 6s 163us/step - loss: 0.0089 - acc: 0.9968 - val_loss: 0.2874 - val_acc: 0.9469\n",
      "Epoch 11/12\n",
      "37500/37500 [==============================] - 6s 161us/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.2734 - val_acc: 0.9481\n",
      "Epoch 12/12\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.3153 - val_acc: 0.9443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1468a2a5240>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_img_train_normalize,\n",
    "          y_label_train_OneHot, \n",
    "          validation_split=0.25,\n",
    "          epochs=12, batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 108us/step\n",
      "\n",
      "accuracy 0.9422499885559082\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_img_test_normalize, y_label_test_OneHot)\n",
    "print()\n",
    "print('accuracy',scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss=\"categorical_crossentropy\", accuracy 0.7226\n",
    "loss=\"MSE\", accuracy 0.7109\n",
    "loss=\"binary_crossentropy\", accuracy 0.9422499885559082"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Day71-使用損失函數_HW.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
